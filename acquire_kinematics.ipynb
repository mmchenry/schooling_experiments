{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook outlines a workflow and executes key code for batch processing of autotracking.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths, packages, and parameters\n",
    "You'll need to execute the next cell for all of the code that follows. \n",
    "\n",
    "Make sure that the root_path and local_path are correct for your system.\n",
    "\n",
    "The root_path is the path to the folder containing the data, and video folders.\n",
    "\n",
    "local_path needs to be a directory on a local drive for writing binary video files for TGrabs/TRex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The project name need to match a directory name within the root path\n",
    "proj_name = 'RN_Prop'\n",
    "\n",
    "# Other details about the project\n",
    "species    = 'rummy_nose'\n",
    "exp_type   = 'prop_neo'\n",
    "\n",
    "# font size for GUIs\n",
    "font_size = 30\n",
    "\n",
    "# Repeated measures for each calibration video\n",
    "num_reps = 3\n",
    "\n",
    "# Max number of frames for the mean image\n",
    "max_num_frame_meanimage = 300\n",
    "\n",
    "# Raw and processed video extensions\n",
    "vid_ext_raw = 'MOV'\n",
    "vid_ext_proc = 'mp4'\n",
    "\n",
    "# Installed packages\n",
    "import os\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# Our own modules\n",
    "import def_acquisition as da\n",
    "import def_paths as dp\n",
    "import video_preprocess as vp\n",
    "import acqfunctions as af\n",
    "import gui_functions as gf\n",
    "\n",
    "# DEFINE ROOT PATH ============================================================\n",
    "\n",
    "# Matt's laptop\n",
    "if (platform.system() == 'Darwin') and (os.path.expanduser('~')=='/Users/mmchenry'):\n",
    "    \n",
    "    root_path = '/Users/mmchenry/Documents/Projects/waketracking'\n",
    "\n",
    "# Matt on PopOS! machine\n",
    "elif (platform.system() == 'Linux') and (os.path.expanduser('~')=='/home/mmchenry'):\n",
    "\n",
    "    # root_path = '/home/mmchenry/Documents/wake_tracking'\n",
    "    root_path = '/mnt/schooling/TRex'\n",
    "    local_path = '/home/mmchenry/Documents/wake_tracking/video/binary'\n",
    "\n",
    "# Ashley on Linux\n",
    "elif (platform.system() == 'Linux') and (os.path.expanduser('~')=='/home/anpetey'):\n",
    "\n",
    "    root_path = '/vortex/schooling/TRex'\n",
    "    local_path = '/home/anpetey/Documents/wake_tracking/video/binary'\n",
    "\n",
    "# Catch alternatives\n",
    "else:\n",
    "    raise ValueError('Do not recognize this account -- add lines of code to define paths here')\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "# Check for local path definition\n",
    "if not 'local_path' in locals():\n",
    "    raise ValueError('Local path not defined')\n",
    "\n",
    "# Check paths\n",
    "if not os.path.exists(root_path):\n",
    "    raise ValueError('Root path does not exist: ' + root_path)\n",
    "elif not os.path.exists(local_path):\n",
    "    raise ValueError('Local path does not exist: ' + local_path)\n",
    "\n",
    "# Get paths \n",
    "path = dp.give_paths(root_path, proj_name)\n",
    "\n",
    "# Function that generates a filename\n",
    "def generate_filename(date, sch_num, trial_num=None):\n",
    "    if trial_num is None:\n",
    "        return date + '_sch' + str(int(sch_num)).zfill(3)\n",
    "    else:\n",
    "        return date + '_sch' + str(int(sch_num)).zfill(3) + '_tr' + str(int(trial_num)).zfill(3)\n",
    "\n",
    "# If using Jupyter notebook outside of VS Code, enable auto-reload\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive video measurements\n",
    "This section interactively prompts a user for what's needed to preprocess videos from a particular schedule. It prompts the user for information that it needs to create a mask, perform a spatial calibration, and select threshold and blob area values for the image processing by TGrabs and TRex."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select schedule, check for problems in recordings\n",
    "Note: need to run this for cells below.\n",
    "\n",
    "Here we prompt the user to select which schedule to choose for preprocessing. Along the way, it checks for the following:\n",
    "- That the experiment_log.csv and recording_log.csv lists include all trials in the schedule.\n",
    "- Compares the schedules in the project against video recordings \n",
    "- It compares the duration of recorded videos to what was expected in the schedule and alerts user of large differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T21:41:23.796130572Z",
     "start_time": "2023-07-11T21:41:20.109209678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "WARNING: The number of rows of the schedule do not match the current catalog from experiment_log.csv.\n",
      " \n",
      "Note that the following trials in the schedule do not have matching videos in experiment_log.csv:\n",
      "   1\n",
      "   3\n",
      " \n",
      "All trials in the schedule have matching videos in recording_log.csv\n",
      " \n",
      "Added time code data to experiment_log.csv\n"
     ]
    }
   ],
   "source": [
    "# Find matching directories between the schedule and video directories\n",
    "matching_sch, nonmatching_sch = vp.find_schedule_matches(path['sch'], path['vidin'])\n",
    "\n",
    "# if matching_directories is empty, then say so and exit\n",
    "if len(matching_sch) == 0:\n",
    "    print(' ')\n",
    "    print(\"No matching directories found between the dates in the schedule list and the dates in the video directory.\")\n",
    "    print('Schedule directory:',  path['sch'])\n",
    "    print('Video directory:',     path['vidin'])\n",
    "    print(' ')\n",
    "    sys.exit()\n",
    "\n",
    "# If there are matches . . .\n",
    "else:\n",
    "    # if nonmatching_directories is not empty, then print the list of nonmatching directories\n",
    "    if len(nonmatching_sch) > 0:\n",
    "        print(\"Note that the following schedules do not have matching dates in the video directory:\")\n",
    "        for directory in nonmatching_sch:\n",
    "            print('   ' + directory)\n",
    "\n",
    "    # Use the list of matching directories for user selection\n",
    "    analysis_schedule = gf.select_item(matching_sch, 'Select which schedule to work on', font_size=font_size)\n",
    "\n",
    "    # define sch_num as the number given from the last two characters of analysis_schedule\n",
    "    sch_num = int(analysis_schedule[-2:])\n",
    "\n",
    "    # define sch_date as the date given from the first 10 characters of analysis_schedule\n",
    "    sch_date = analysis_schedule[:10]\n",
    "\n",
    "# Get schedule data\n",
    "sch = pd.read_csv(path['sch'] + os.sep + analysis_schedule + '.csv')\n",
    "\n",
    "# Extract experiment catalog info\n",
    "cat = af.get_cat_info(path['cat'], include_mode='both', exclude_mode='calibration')\n",
    "if len(cat) == 0:\n",
    "    raise ValueError('No videos requested to work on from experiment_log.' + \\\n",
    "                     ' Both the columns \\'analyze\\' and \\'make_video\\' must be' + \\\n",
    "                     ' set to 1 for pre-processing.')\n",
    "\n",
    "# Extract experiment log info\n",
    "log = pd.read_csv(path['data'] + os.sep + 'recording_log.csv')\n",
    "\n",
    "# Return a version of cat for all matches of the sch_num column that matches sch_num\n",
    "cat_curr = cat[cat['sch_num'] == sch_num]\n",
    "\n",
    "# Return a version of log for all matches of the sch_num column that matches sch_num and all matches of the sch_date column that matches sch_date\n",
    "log_curr = log[(log['sch_num'] == sch_num) & (log['date'] == sch_date)]\n",
    "\n",
    "# Check if the number of rows of the schedule matches the number of rows of the current catalog\n",
    "if cat_curr.shape[0]!=sch.shape[0]:\n",
    "    print(' ')\n",
    "    print('WARNING: The number of rows of the schedule do not match the current catalog from experiment_log.csv.')\n",
    "\n",
    "# Make list of any trial numbers in sch that do not match any trial num in cat_curr\n",
    "missing_trials_cat = [trial for trial in sch['trial_num'] if trial not in cat_curr['trial_num'].values]\n",
    "missing_trials_log = [trial for trial in sch['trial_num'] if trial not in log_curr['trial_num'].values]\n",
    "\n",
    "# If there are missing trials, then print the list of missing trials\n",
    "print(' ')\n",
    "if len(missing_trials_cat) > 0:\n",
    "    print(\"Note that the following trials in the schedule do not have matching videos in experiment_log.csv:\")\n",
    "    for trial in missing_trials_cat:\n",
    "        print('   ' + str(trial))\n",
    "else:\n",
    "    print('All trials in the schedule have matching videos in experiment_log.csv')\n",
    "\n",
    "# If there are missing trials, then print the list of missing trials\n",
    "print(' ')\n",
    "if len(missing_trials_log) > 0:\n",
    "    print(\"Note that the following trials in the schedule do not have matching videos in recording_log.csv:\")\n",
    "    for trial in missing_trials_log:\n",
    "        print('   ' + str(trial))\n",
    "else:\n",
    "    print('All trials in the schedule have matching videos in recording_log.csv')\n",
    "\n",
    "# Path to all videos for the current date\n",
    "vid_path = path['vidin'] + os.sep +  sch_date\n",
    "\n",
    "# Flag any large differences in video duration from experiment log, return list of videos to be processed\n",
    "vid_files = vp.check_video_duration(vid_path, sch, cat, vid_ext=vid_ext_raw, thresh_time=3.0)\n",
    "\n",
    "# Read the full cat file\n",
    "cat_raw = pd.read_csv(path['cat'])\n",
    "\n",
    "# Check if any timecode values have not been specified\n",
    "all_timecodes_specified = False\n",
    "if 'timecode_start' in cat_raw.columns:\n",
    "    # Filter the DataFrame based on the condition\n",
    "    filtered_data = cat_raw[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num)]\n",
    "\n",
    "    # Check if all timecode values are specified\n",
    "    all_timecodes_specified = filtered_data['timecode_start'].notnull().all()\n",
    "    \n",
    "# If there's any missing calibration values . . .\n",
    "if True: #not all_timecodes_specified:\n",
    "    # Add timecode data to cat_raw\n",
    "    cat_raw = vp.add_start_timecodes(vid_files, vid_path, cat_raw)\n",
    "\n",
    "    # Write cat_raw, if it has the same dimensions, or one new column\n",
    "    cat_raw.to_csv(path['cat'], index=False)\n",
    "    print(' ')\n",
    "    print('Added time code data to experiment_log.csv')\n",
    "else:\n",
    "    print(' ')\n",
    "    print('Time code data already exists in experiment_log.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a mask image\n",
    "You will want to choose a region of interest that is just outside of the water line within the arena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mask filename\n",
    "mask_filename = generate_filename(sch_date, sch_num, trial_num=None)\n",
    "mask_path = path['mask'] + os.sep + mask_filename + '_mask.jpg'\n",
    "\n",
    "# If the mask file does not exist, then create it\n",
    "if True: #not os.path.exists(mask_path):\n",
    "   centroid = gf.create_mask_for_batch(vid_path+os.sep+vid_files[0], mask_path)\n",
    "\n",
    "   # Read the full cat file\n",
    "   cat_raw = pd.read_csv(path['cat'])\n",
    "\n",
    "   # Get the size of the cat_raw\n",
    "   cat_raw_size = cat_raw.shape\n",
    "\n",
    "   # Determine if roi centroid values already exsist in cat_raw where date==sch_date and sch_num==sch_num\n",
    "   roi_x_exists = cat_raw.loc[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num), 'roi_x'].values\n",
    "\n",
    "   roi_y_exists = cat_raw.loc[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num), 'roi_y'].values\n",
    "\n",
    "   # If there's any missing roi values . . .\n",
    "   if max(np.isnan(roi_x_exists)):\n",
    "        # Find video_filename for calibration from cat_raw: where the date matches sch_date and the sch_num is 999\n",
    "        cal_video_filename = cat_raw[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == 999)]['video_filename'].values\n",
    "\n",
    "        # Add roi centroid value to cat_raw.roi_x and cat_raw.roi_y where sch_num=sch_num\n",
    "        cat_raw.loc[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num), 'roi_x'] = centroid[0]\n",
    "        cat_raw.loc[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num), 'roi_y'] = centroid[1]\n",
    "\n",
    "        # Write cat_raw, if it has the same dimensions, or one new column\n",
    "        if (cat_raw.shape[0] == cat_raw_size[0]) and \\\n",
    "            (cat_raw.shape[1] == cat_raw_size[1]):\n",
    "            cat_raw.to_csv(path['cat'], index=False)\n",
    "            print(' ')\n",
    "            print('Added roi centroid values to experiment_log.csv')\n",
    "        else:\n",
    "            # raise exception\n",
    "            raise ValueError('cat_raw has the wrong dimensions-- cannot write the roi centroid data to experiment_log')\n",
    "\n",
    "\n",
    "else:\n",
    "    print(' ')\n",
    "    print('Mask file and roi already exists. Using existing mask file: ' + mask_path)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run spatial calibration\n",
    "Prompts user to conduct repeated measures for the calibration. Note that you need to know the actual length in centimeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the full cat file\n",
    "cat_raw = pd.read_csv(path['cat'])\n",
    "\n",
    "# Get the size of the cat_raw\n",
    "cat_raw_size = cat_raw.shape\n",
    "\n",
    "# Determine if cm_per_pix values already exsist in cat_raw where date==sch_date and sch_num==sch_num\n",
    "cm_per_pix_exists = cat_raw.loc[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num), 'cm_per_pix'].values\n",
    "\n",
    "# If there's any missing calibration values . . .\n",
    "if max(np.isnan(cm_per_pix_exists)):\n",
    "\n",
    "    # Find video_filename for calibration from cat_raw: where the date matches sch_date and the sch_num is 999\n",
    "    cal_video_filename = cat_raw[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == 999)]['video_filename'].values\n",
    "\n",
    "    # Define the full path to the calibration video\n",
    "    full_vid_path = vid_path + os.sep + cal_video_filename[0] + '.' + vid_ext_raw\n",
    "\n",
    "    # Raise exception if cal_video_filename has a length of zero\n",
    "    if len(cal_video_filename) == 0:\n",
    "        raise ValueError('The calibration video does not exist in the catalog file')\n",
    "    # Or, more than one\n",
    "    elif len(cal_video_filename) > 1:\n",
    "        raise ValueError('More than one calibration video exists in the catalog file')\n",
    "\n",
    "    # Raise exception if cal_video_filename is not in vid_path\n",
    "    if not os.path.exists(full_vid_path):\n",
    "        raise ValueError('The calibration video does not exist in the video directory: ' + full_vid_path)\n",
    "\n",
    "    # Run the spatial calibration\n",
    "    cm_per_pix = gf.run_spatial_calibration(full_vid_path, reps=3, font_size=font_size)\n",
    "\n",
    "    # Add cm_per_pix value to cat_raw.cm_per_pix where sch_num=sch_num\n",
    "    cat_raw.loc[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num), 'cm_per_pix'] = cm_per_pix\n",
    "\n",
    "    # Write cat_raw, if it has the same dimensions, or one new column\n",
    "    if (cat_raw.shape[0] == cat_raw_size[0]) and \\\n",
    "        (cat_raw.shape[1] == cat_raw_size[1]):\n",
    "        cat_raw.to_csv(path['cat'], index=False)\n",
    "        print(' ')\n",
    "        print('Added cm_per_pix values to experiment_log.csv')\n",
    "    else:\n",
    "        # raise exception\n",
    "        raise ValueError('cat_raw has the wrong dimensions-- cannot write the time code data to experiment_log')\n",
    "    \n",
    "else:\n",
    "    print(' ')\n",
    "    print('cm_per_pix values already exist in experiment_log.csv for the current date and schedule number.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mean image\n",
    "A mean image is created from multiple videos in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mask filename\n",
    "mask_filename = generate_filename(sch_date, sch_num, trial_num=None)\n",
    "mask_path = path['mask'] + os.sep + mask_filename + '_mask.jpg'\n",
    "\n",
    "# Mean image path\n",
    "mean_image_path = path['mean'] + os.sep + mask_filename + '_mean.jpg'\n",
    "\n",
    "# If the mean image does not exist, then create it\n",
    "if not os.path.exists(mask_path):\n",
    "\n",
    "    # Find the mask\n",
    "    im_mask, mask_perim = vp.get_mask(mask_path)\n",
    "\n",
    "    # Make mean image\n",
    "    mean_image = vp.make_max_mean_image(cat_curr, sch, vid_path, max_num_frame_meanimage, im_mask=im_mask, mask_perim=mask_perim, im_crop=True)\n",
    "\n",
    "    # Save the mean image\n",
    "    mean_image_path = path['mean'] + os.sep + mask_filename + '_mean.jpg'\n",
    "    cv2.imwrite(mean_image_path, mean_image)\n",
    "\n",
    "# If the mean image does exist, then read it\n",
    "else:\n",
    "    # Read the mean image\n",
    "    mean_image = cv2.imread(mean_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Display the binary image\n",
    "gf.create_cv_window('Mean image')\n",
    "cv2.imshow('Mean image', mean_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select threshold and blob area\n",
    "\n",
    "- Select the lowest threshold possible, without the margins of each fish looking fuzzy\n",
    "\n",
    "- Select the range of areas that just barely include individual fish. Exclude fish that are touching area other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T21:40:56.447770862Z",
     "start_time": "2023-07-11T21:40:56.396828949Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the full cat file\n",
    "cat_raw = pd.read_csv(path['cat'])\n",
    "\n",
    "# Get the size of the cat_raw\n",
    "cat_raw_size = cat_raw.shape\n",
    "\n",
    "# Check if 'min_area' column exists in cat_raw and does not have nans\n",
    "if 'min_area' not in cat_raw.columns or cat_raw['min_area'].isnull().any():\n",
    "\n",
    "    # Get the mask\n",
    "    mask_filename = generate_filename(sch_date, sch_num, trial_num=None)\n",
    "    mask_path = path['mask'] + os.sep + mask_filename + '_mask.jpg'\n",
    "    im_mask, mask_perim = vp.get_mask(mask_path)\n",
    "\n",
    "    # Get the mean image\n",
    "    mean_image_path = path['mean'] + os.sep + mask_filename + '_mean.jpg'\n",
    "    mean_image = cv2.imread(mean_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # read first frame of first video\n",
    "    vid_path_curr = vid_path + os.sep + vid_files[0]\n",
    "    vid = cv2.VideoCapture(vid_path_curr)\n",
    "    im_start = vp.read_frame(vid, 0, im_mask=im_mask, mask_perim=mask_perim, im_crop=True)\n",
    "    vid.release()\n",
    "\n",
    "    # Select the threshold\n",
    "    threshold, im_thresholded = gf.interactive_threshold(im_start, mean_image)\n",
    "    print('Selected threshold = ' + str(threshold))\n",
    "\n",
    "    # Select the bounds of blob area\n",
    "    print(' ')\n",
    "    print('Select the bounds of blob area that include just a single fish')\n",
    "    min_area, max_area = gf.interactive_blob_filter(im_start, mean_image, threshold)\n",
    "    print('Selected min_area = ' + str(min_area))\n",
    "    print('Selected max_area = ' + str(max_area))\n",
    "\n",
    "    # Save results to experiment_log.csv\n",
    "    cat_raw.loc[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num), 'threshold'] = threshold\n",
    "    cat_raw.loc[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num), 'min_area'] = min_area\n",
    "    cat_raw.loc[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num), 'max_area'] = max_area\n",
    "\n",
    "    # Write cat_raw, if it has the same dimensions, or one new column\n",
    "    cat_raw.to_csv(path['cat'], index=False)\n",
    "    print(' ')\n",
    "    print('Added threshold and area values to experiment_log.csv')\n",
    "\n",
    "else:\n",
    "    print(' ')\n",
    "    print('Threshold and area values already exist in experiment_log.csv for the current date and schedule number.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate binary videos\n",
    "\n",
    "Here we use the threshold and area values to generate black-and-white images of the school.\n",
    "\n",
    "This can be performed on a single video, all videos in a schedule in succession, or using parallel processing (the fastest option)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-11T21:49:28.290005746Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Get the mask\n",
    "mask_filename = generate_filename(sch_date, sch_num, trial_num=None)\n",
    "mask_path = path['mask'] + os.sep + mask_filename + '_mask.jpg'\n",
    "im_mask, mask_perim = vp.get_mask(mask_path)\n",
    "\n",
    "# Get the mean image\n",
    "mean_image_path = path['mean'] + os.sep + mask_filename + '_mean.jpg'\n",
    "mean_image = cv2.imread(mean_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Single video address in cat_curr\n",
    "index = 0\n",
    "row = cat_curr.iloc[0]\n",
    "\n",
    "# Paths for input and output videos\n",
    "vid_path_in = vid_path + os.sep + row['video_filename'] + '.' + vid_ext_raw\n",
    "vid_file_out = generate_filename(row['date'], row['sch_num'], trial_num=row['trial_num'])\n",
    "vid_path_out = local_path + os.sep + vid_file_out + '.' + vid_ext_proc\n",
    "\n",
    "# Set bounds of the area for blobs\n",
    "min_area = int(row['min_area']/4)\n",
    "max_area = int(10*row['max_area'])\n",
    "\n",
    "print('Video in: '  + vid_path_in)\n",
    "print('Video out: ' + vid_path_out)\n",
    "\n",
    "status_txt = 'Trial ' + str(row['trial_num'])\n",
    "\n",
    "# Generate and save binary movie\n",
    "vp.make_binary_movie(vid_path_in, vid_path_out, mean_image, row['threshold'], min_area, max_area, \\\n",
    "                        im_mask=im_mask, mask_perim=mask_perim, im_crop=True, status_txt=status_txt, echo=True, blob_color='grayscale')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One video at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mask\n",
    "mask_filename = generate_filename(sch_date, sch_num, trial_num=None)\n",
    "mask_path = path['mask'] + os.sep + mask_filename + '_mask.jpg'\n",
    "im_mask, mask_perim = vp.get_mask(mask_path)\n",
    "\n",
    "# Get the mean image\n",
    "mean_image_path = path['mean'] + os.sep + mask_filename + '_mean.jpg'\n",
    "mean_image = cv2.imread(mean_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Loop thru each row of cat_curr\n",
    "for index, row in cat_curr.iterrows():\n",
    "\n",
    "    # Paths for input and output videos\n",
    "    vid_path_in = vid_path + os.sep + row['video_filename'] + '.' + vid_ext_raw\n",
    "    vid_file_out = generate_filename(row['date'], row['sch_num'], trial_num=row['trial_num'])\n",
    "    vid_path_out = local_path + os.sep + vid_file_out + '.' + vid_ext_proc\n",
    "\n",
    "    # Set bounds of the area for blobs\n",
    "    min_area = int(row['min_area']/4)\n",
    "    max_area = int(10*row['max_area'])\n",
    "\n",
    "    print('Video in: '  + vid_path_in)\n",
    "    print('Video out: ' + vid_path_out)\n",
    "\n",
    "    status_txt = 'Trial ' + str(row['trial_num'])\n",
    "\n",
    "    # Generate and save binary movie\n",
    "    vp.make_binary_movie(vid_path_in, vid_path_out, mean_image, row['threshold'], min_area, max_area, \\\n",
    "                         im_mask=im_mask, mask_perim=mask_perim, im_crop=True, status_txt=status_txt, echo=True, blob_color='white')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the mask\n",
    "mask_filename = generate_filename(sch_date, sch_num, trial_num=None)\n",
    "mask_path = path['mask'] + os.sep + mask_filename + '_mask.jpg'\n",
    "im_mask, mask_perim = vp.get_mask(mask_path)\n",
    "\n",
    "# Get the mean image\n",
    "mean_image_path = path['mean'] + os.sep + mask_filename + '_mean.jpg'\n",
    "mean_image = cv2.imread(mean_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Define a function to process each row in parallel\n",
    "def process_row(row):\n",
    "    # Paths for input and output videos\n",
    "    vid_path_in = vid_path + os.sep + row['video_filename'] + '.' + vid_ext_raw\n",
    "    vid_file_out = generate_filename(row['date'], row['sch_num'], trial_num=row['trial_num'])\n",
    "    vid_path_out = local_path + os.sep + vid_file_out + '.' + vid_ext_proc\n",
    "\n",
    "    # Set bounds of the area for blobs\n",
    "    min_area = int(row['min_area'] / 4)\n",
    "    max_area = int(10*row['max_area'])\n",
    "\n",
    "    status_txt = 'Trial ' + str(row['trial_num'])\n",
    "\n",
    "    # Generate and save binary movie\n",
    "    vp.make_binary_movie(vid_path_in, vid_path_out, mean_image, row['threshold'], min_area, max_area,\n",
    "        im_mask=im_mask, mask_perim=mask_perim, im_crop=True, status_txt=status_txt, echo=True, blob_color='grayscale')\n",
    "\n",
    "# Create a ThreadPoolExecutor to execute the iterations in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Loop thru each row of cat_curr and submit each iteration as a separate task\n",
    "    futures = [executor.submit(process_row, row) for _, row in cat_curr.iterrows()]\n",
    "\n",
    "    # Wait for all tasks to complete\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "# Calculate the total execution time\n",
    "execution_time = (time.time() - start_time)/60/60\n",
    "print(\"Total execution time: {:.2f} hours\".format(execution_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# tRex and tGrabs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Parameters\n",
    "\n",
    "Parameters are described in the documentation for [TGrabs](https://trex.run/docs/parameters_tgrabs.html) and [TRex](https://trex.run/docs/parameters_trex.html).\n",
    "\n",
    "These lists of parameters will be passed to TGrabs and TRex. If there is not already a column for that parameter, then it will be added to cat (i.e. experiment_log.csv) with the default values specified below. Those defaults may be overridden by keying values into experiment_log.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter list to use by TGrabs, along with default\n",
    "param_list_tgrabs = [\n",
    "    #['threshold','20'],\n",
    "    ['averaging_method','mode'],\n",
    "    ['average_samples','150'],\n",
    "    ['blob_size_range','[0.0001,5000000]'],\n",
    "    ['meta_conditions',exp_type],\n",
    "    ['meta_species',species]\n",
    "   # ['meta_misc','school_ABC']\n",
    "    ]\n",
    "\n",
    "# Specify list of parameter values for TRex, all listed as strings\n",
    "param_list_trex = [\n",
    "    #['track_threshold','20'],\n",
    "    #['blob_size_ranges','[0.03,1.5]'],\n",
    "    ['track_max_speed','70'],\n",
    "    ['output_format','npz'],\n",
    "    ['output_invalid_value','nan'],\n",
    "    # ['gui_zoom_limit','[100,100]'],\n",
    "    ['gui_show_posture','false'],\n",
    "    ['gui_show_paths','false'],\n",
    "    ['gui_show_outline', 'true'], \n",
    "    ['gui_show_midline', 'true'], \n",
    "    ['gui_show_blobs', 'true'],\n",
    "    ['calculate_posture','true'],\n",
    "    ['gui_show_number_individuals', 'true']\n",
    "    ]\n",
    "\n",
    "# Map 'cat' column names to TRex parameter names (no default values)\n",
    "cat_to_trex = [\n",
    "    ['fish_num','track_max_individuals'],\n",
    "    ['cm_per_pix','cm_per_pixel'],\n",
    "    ['frame_rate','frame_rate']\n",
    "    ]\n",
    "\n",
    "# Add default parameter values to all rows\n",
    "af.add_param_vals(path['cat'], param_list_tgrabs, param_list_trex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TGrabs\n",
    "\n",
    "TGrabs generates pv video files from raw videos for TRex tracking.\n",
    "\n",
    "Cell below generates dv videos, which will be used by TRex, from compressed videos.\n",
    "This will be completed for each row of cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TGrabs, or formulate the command-line terminal commands\n",
    "commands = af.run_tgrabs(path['cat'], loc%load_ext autoreload\n",
    "%autoreload 2al_path, path['vidpv'], param_list_tgrabs, vid_ext_proc=vid_ext_proc, use_settings_file=False, run_gui=False, echo=True, run_command=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TRex\n",
    "Uses the parameter names given in param_list_trex and cat_to_trex to generate the command-line terminal commands to run TRex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Run TRex, or formulate the command-line terminal commands\n",
    "commands = af.run_trex(path['cat'], path['vidpv'], path['data_raw'], param_list_trex, cat_to_trex, run_gui=False, output_posture=True, echo=True, run_command=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export TRex data in mat format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract experiment catalog info\n",
    "cat = af.get_cat_info(path['cat'], include_mode='matlab', exclude_mode='calibration')\n",
    "\n",
    "# Convert all npz files for an experiment to mat files.\n",
    "da.raw_to_mat(cat, path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Housecleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Delete the local binary videos that match the pv videos\n",
    "af.delete_matching_files(local_path, path['vidpv'])\n",
    "git"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "71dac57fef06cf0555e23a411fcaf11d6b3df35474a6cffaa58a5c856d74addb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
