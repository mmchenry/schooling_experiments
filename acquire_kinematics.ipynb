{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook outlines a workflow and executes key code for batch processing of autotracking.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths, packages, and parameters\n",
    "You'll need to execute the next cell for all of the code that follows. \n",
    "\n",
    "Make sure that the root_path and local_path are correct for your system.\n",
    "\n",
    "The root_path is the path to the folder containing the data, and video folders.\n",
    "\n",
    "local_path needs to be a directory on a local drive for writing binary video files for TGrabs/TRex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform \n",
    "\n",
    "# Matt's laptop\n",
    "if (platform.system() == 'Darwin') and (os.path.expanduser('~')=='/Users/mmchenry'):\n",
    "    \n",
    "    root_path = '/Users/mmchenry/Documents/Projects/waketracking'\n",
    "\n",
    "# Matt on PopOS! machine\n",
    "elif (platform.system() == 'Linux') and (os.path.expanduser('~')=='/home/mmchenry'):\n",
    "\n",
    "    # root_path = '/home/mmchenry/Documents/wake_tracking'\n",
    "    root_path = '/mnt/schooling/TRex'\n",
    "    local_path = '/home/mmchenry/Documents/wake_tracking/video/binary'\n",
    "\n",
    "# Ashley on Linux\n",
    "elif (platform.system() == 'Linux') and (os.path.expanduser('~')=='/home/anpetey'):\n",
    "\n",
    "    root_path = '/vortex/schooling/TRex'\n",
    "\n",
    "# Catch alternatives\n",
    "else:\n",
    "    raise ValueError('Do not recognize this account -- add lines of code to define paths here')\n",
    "\n",
    "# Check paths\n",
    "if not os.path.exists(root_path):\n",
    "    raise ValueError('Root path does not exist: ' + root_path)\n",
    "elif not os.path.exists(local_path):\n",
    "    raise ValueError('Local path does not exist: ' + local_path)\n",
    "\n",
    "# import sys\n",
    "import def_acquisition as da\n",
    "import def_paths as dp\n",
    "import video_preprocess as vp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import acqfunctions as af\n",
    "import videotools as vt\n",
    "# import tkinter as tk\n",
    "# import screeninfo\n",
    "import gui_functions as gf\n",
    "\n",
    "# The project name need to match a directory name within the root path\n",
    "proj_name = 'RN_Ramp_Debug'\n",
    "\n",
    "# Get paths (specific to system running code)\n",
    "path = dp.give_paths(root_path, proj_name)\n",
    "\n",
    "# Raw and processed video extensions\n",
    "vid_ext_raw = 'MOV'\n",
    "vid_ext_proc = 'mp4'\n",
    "\n",
    "# font size for GUIs\n",
    "font_size = 40\n",
    "\n",
    "# Repeated measures for each calibration video\n",
    "num_reps = 3\n",
    "\n",
    "# Max number of frames for the mean image\n",
    "max_num_frame_meanimage = 300\n",
    "\n",
    "# Function that generates a filename\n",
    "def generate_filename(date, sch_num, trial_num=None):\n",
    "    if trial_num is None:\n",
    "        return date + '_sch' + str(sch_num).zfill(3)\n",
    "    else:\n",
    "        return date + '_sch' + str(sch_num).zfill(3) + '_tr' + str(trial_num).zfill(3)\n",
    "\n",
    "# If using Jupyter notebook, enable auto-reload\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive video measurements\n",
    "This section interactively prompts a user for what's needed to preprocess videos from a particular schedule. It prompts the user for information that it needs to create a mask, perform a spatial calibration, and select threshold and blob area values for the image processing by TGrabs and TRex."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select schedule, check for problems in recordings\n",
    "Note: need to run this for cells below.\n",
    "\n",
    "Here we prompt the user to select which schedule to choose for preprocessing. Along the way, it checks for the following:\n",
    "- That the experiment_log.csv and recording_log.csv lists include all trials in the schedule.\n",
    "- Compares the schedules in the project against video recordings \n",
    "- It compares the duration of recorded videos to what was expected in the schedule and alerts user of large differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find matching directories between the schedule and video directories\n",
    "matching_sch, nonmatching_sch = vp.find_schedule_matches(path['sch'], path['vidin'])\n",
    "\n",
    "# if matching_directories is empty, then say so and exit\n",
    "if len(matching_sch) == 0:\n",
    "    print(' ')\n",
    "    print(\"No matching directories found between the dates in the schedule list and the dates in the video directory.\")\n",
    "    print('Schedule directory:', path['sch'])\n",
    "    print('Video directory:', path['vidin'])\n",
    "    print(' ')\n",
    "    sys.exit()\n",
    "\n",
    "#  If there are matches . . .\n",
    "else:\n",
    "    # if nonmatching_directories is not empty, then print the list of nonmatching directories\n",
    "    if len(nonmatching_sch) > 0:\n",
    "        print(\"Note that the following schedules do not have matching dates in the video directory:\")\n",
    "        for directory in nonmatching_sch:\n",
    "            print('   ' + directory)\n",
    "\n",
    "    # Use the list of matching directories for user selection\n",
    "    analysis_schedule = gf.select_item(matching_sch, 'Select which schedule to work on', font_size=font_size)\n",
    "\n",
    "    # define sch_num as the number given from the last two characters of analysis_schedule\n",
    "    sch_num = int(analysis_schedule[-2:])\n",
    "\n",
    "    # define sch_date as the date given from the first 10 characters of analysis_schedule\n",
    "    sch_date = analysis_schedule[:10]\n",
    "\n",
    "# Get schedule data\n",
    "sch = pd.read_csv(path['sch'] + os.sep + analysis_schedule + '.csv')\n",
    "\n",
    "# Extract experiment catalog info\n",
    "cat = af.get_cat_info(path['cat'], include_mode='analyze', exclude_mode='calibration')\n",
    "if len(cat) == 0:\n",
    "    raise ValueError('No videos found in catalog file. the column \\'analyze\\' must be set to one to be included in this analysis')\n",
    "\n",
    "# Extract experiment log info\n",
    "log = pd.read_csv(path['data'] + os.sep + 'recording_log.csv')\n",
    "\n",
    "# Return a version of cat for all matches of the sch_num column that matches sch_num\n",
    "cat_curr = cat[cat['sch_num'] == sch_num]\n",
    "\n",
    "# Return a version of log for all matches of the sch_num column that matches sch_num and all matches of the sch_date column that matches sch_date\n",
    "log_curr = log[(log['sch_num'] == sch_num) & (log['date'] == sch_date)]\n",
    "\n",
    "# Check if the number of rows of the schedule matches the number of rows of the current catalog\n",
    "if cat_curr.shape[0]!=sch.shape[0]:\n",
    "    raise ValueError('The number of rows of the schedule should match the current catalog.')\n",
    "\n",
    "# Make list of any trial numbers in sch that do not match any trial num in cat_curr\n",
    "missing_trials_cat = [trial for trial in sch['trial_num'] if trial not in cat_curr['trial_num'].values]\n",
    "missing_trials_log = [trial for trial in sch['trial_num'] if trial not in log_curr['trial_num'].values]\n",
    "\n",
    "# If there are missing trials, then print the list of missing trials\n",
    "print(' ')\n",
    "if len(missing_trials_cat) > 0:\n",
    "    print(\"Note that the following trials in the schedule do not have matching videos in experiment_log.csv:\")\n",
    "    for trial in missing_trials_cat:\n",
    "        print('   ' + str(trial))\n",
    "else:\n",
    "    print('All trials in the schedule have matching videos in experiment_log.csv')\n",
    "\n",
    "# If there are missing trials, then print the list of missing trials\n",
    "print(' ')\n",
    "if len(missing_trials_log) > 0:\n",
    "    print(\"Note that the following trials in the schedule do not have matching videos in recording_log.csv:\")\n",
    "    for trial in missing_trials_log:\n",
    "        print('   ' + str(trial))\n",
    "else:\n",
    "    print('All trials in the schedule have matching videos in recording_log.csv')\n",
    "\n",
    "# Path to all videos for the current date\n",
    "vid_path = path['vidin'] + os.sep +  sch_date\n",
    "\n",
    "# Flag any large differences in video duration from experiment log, return list of videos to be processed\n",
    "vid_files = vp.check_video_duration(vid_path, sch, cat, vid_ext=vid_ext_raw, thresh_time=3.0)\n",
    "\n",
    "# Read the full cat file\n",
    "cat_raw = pd.read_csv(path['cat'])\n",
    "\n",
    "# Get the size of the cat_raw\n",
    "cat_raw_size = cat_raw.shape\n",
    "\n",
    "# Check if any timecode values have not been specified\n",
    "all_timecodes_specified = False\n",
    "if 'timecode_start' in cat_raw.columns:\n",
    "    # Filter the DataFrame based on the condition\n",
    "    filtered_data = cat_raw[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num)]\n",
    "\n",
    "    # Check if all timecode values are specified\n",
    "    all_timecodes_specified = filtered_data['timecode_start'].notnull().all()\n",
    "    \n",
    "# If there's any missing calibration values . . .\n",
    "if not all_timecodes_specified:\n",
    "    # Add timecode data to cat_raw\n",
    "    cat_raw = vp.add_start_timecodes(vid_files, vid_path, cat_raw)\n",
    "\n",
    "    # Write cat_raw, if it has the same dimensions, or one new column\n",
    "    if ((cat_raw.shape[0] == cat_raw_size[0]) and \\\n",
    "        (cat_raw.shape[1] in (cat_raw_size[1], cat_raw_size[1]+1))):\n",
    "        cat_raw.to_csv(path['cat'], index=False)\n",
    "        print(' ')\n",
    "        print('Added time code data to experiment_log.csv')\n",
    "    else:\n",
    "        # raise exception\n",
    "        raise ValueError('cat_raw has the wrong dimensions-- cannot write the time code data to experiment_log')\n",
    "else:\n",
    "    print(' ')\n",
    "    print('Time code data already exists in experiment_log.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a mask image\n",
    "You will want to choose a region of interest that is just outside of the water line within the arena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mask filename\n",
    "mask_filename = generate_filename(sch_date, sch_num, trial_num=None)\n",
    "mask_path = path['mask'] + os.sep + mask_filename + '_mask.jpg'\n",
    "\n",
    "# If the mask file does not exist, then create it\n",
    "if not os.path.exists(mask_path):\n",
    "    gf.create_mask_for_batch(vid_path+os.sep+vid_files[0], mask_path)\n",
    "else:\n",
    "    print(' ')\n",
    "    print('Mask file already exists. Using existing mask file: ' + mask_path)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run spatial calibration\n",
    "Prompts user to conduct repeated measures for the calibration. Note that you need to know the actual length in centimeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the full cat file\n",
    "cat_raw = pd.read_csv(path['cat'])\n",
    "\n",
    "# Get the size of the cat_raw\n",
    "cat_raw_size = cat_raw.shape\n",
    "\n",
    "# Determine if cm_per_pix values already exsist in cat_raw where date==sch_date and sch_num==sch_num\n",
    "cm_per_pix_exists = cat_raw.loc[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num), 'cm_per_pix'].values\n",
    "\n",
    "# If there's any missing calibration values . . .\n",
    "if max(np.isnan(cm_per_pix_exists)):\n",
    "\n",
    "    # Find video_filename for calibration from cat_raw: where the date matches sch_date and the sch_num is 999\n",
    "    cal_video_filename = cat_raw[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == 999)]['video_filename'].values\n",
    "\n",
    "    # Define the full path to the calibration video\n",
    "    full_vid_path = vid_path + os.sep + cal_video_filename[0] + '.' + vid_ext_raw\n",
    "\n",
    "    # Raise exception if cal_video_filename has a length of zero\n",
    "    if len(cal_video_filename) == 0:\n",
    "        raise ValueError('The calibration video does not exist in the catalog file')\n",
    "    # Or, more than one\n",
    "    elif len(cal_video_filename) > 1:\n",
    "        raise ValueError('More than one calibration video exists in the catalog file')\n",
    "\n",
    "    # Raise exception if cal_video_filename is not in vid_path\n",
    "    if not os.path.exists(full_vid_path):\n",
    "        raise ValueError('The calibration video does not exist in the video directory: ' + full_vid_path)\n",
    "\n",
    "    # Run the spatial calibration\n",
    "    cm_per_pix = gf.run_spatial_calibration(full_vid_path, reps=3, font_size=font_size)\n",
    "\n",
    "    # Add cm_per_pix value to cat_raw.cm_per_pix where sch_num=sch_num\n",
    "    cat_raw.loc[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num), 'cm_per_pix'] = cm_per_pix\n",
    "\n",
    "    # Write cat_raw, if it has the same dimensions, or one new column\n",
    "    if (cat_raw.shape[0] == cat_raw_size[0]) and \\\n",
    "        (cat_raw.shape[1] == cat_raw_size[1]):\n",
    "        cat_raw.to_csv(path['cat'], index=False)\n",
    "        print(' ')\n",
    "        print('Added cm_per_pix values to experiment_log.csv')\n",
    "    else:\n",
    "        # raise exception\n",
    "        raise ValueError('cat_raw has the wrong dimensions-- cannot write the time code data to experiment_log')\n",
    "    \n",
    "else:\n",
    "    print(' ')\n",
    "    print('cm_per_pix values already exist in experiment_log.csv for the current date and schedule number.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mean image\n",
    "A mean image is created from multiple videos in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mask filename\n",
    "mask_filename = generate_filename(sch_date, sch_num, trial_num=None)\n",
    "mask_path = path['mask'] + os.sep + mask_filename + '_mask.jpg'\n",
    "\n",
    "# Mean image path\n",
    "mean_image_path = path['mean'] + os.sep + mask_filename + '_mean.jpg'\n",
    "\n",
    "# If the mean image does not exist, then create it\n",
    "if not os.path.exists(mask_path):\n",
    "\n",
    "    # Find the mask\n",
    "    im_mask, mask_perim = vp.get_mask(mask_path)\n",
    "\n",
    "    # Make mean image\n",
    "    mean_image = vp.make_max_mean_image(cat_curr, sch, vid_path, max_num_frame_meanimage, im_mask=im_mask, mask_perim=mask_perim, im_crop=True)\n",
    "\n",
    "    # Save the mean image\n",
    "    mean_image_path = path['mean'] + os.sep + mask_filename + '_mean.jpg'\n",
    "    cv2.imwrite(mean_image_path, mean_image)\n",
    "\n",
    "# If the mean image does exist, then read it\n",
    "else:\n",
    "    # Read the mean image\n",
    "    mean_image = cv2.imread(mean_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Display the binary image\n",
    "gf.create_cv_window('Mean image')\n",
    "cv2.imshow('Mean image', mean_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select threshold and blob area\n",
    "\n",
    "- Select the lowest threshold possible, without the margins of each fish looking fuzzy\n",
    "\n",
    "- Select the range of areas that just barely include individual fish. Exclude fish that are touching area other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the full cat file\n",
    "cat_raw = pd.read_csv(path['cat'])\n",
    "\n",
    "# Get the size of the cat_raw\n",
    "cat_raw_size = cat_raw.shape\n",
    "\n",
    "# Check if 'min_area' column exists in cat_raw and does not have nans\n",
    "if True: #'min_area' not in cat_raw.columns or cat_raw['min_area'].isnull().any():\n",
    "\n",
    "    # Get the mask\n",
    "    mask_filename = generate_filename(sch_date, sch_num, trial_num=None)\n",
    "    mask_path = path['mask'] + os.sep + mask_filename + '_mask.jpg'\n",
    "    im_mask, mask_perim = vp.get_mask(mask_path)\n",
    "\n",
    "    # Get the mean image\n",
    "    mean_image_path = path['mean'] + os.sep + mask_filename + '_mean.jpg'\n",
    "    mean_image = cv2.imread(mean_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # read first frame of first video\n",
    "    vid_path_curr = vid_path + os.sep + vid_files[0]\n",
    "    vid = cv2.VideoCapture(vid_path_curr)\n",
    "    im_start = vp.read_frame(vid, 0, im_mask=im_mask, mask_perim=mask_perim, im_crop=True)\n",
    "    vid.release()\n",
    "\n",
    "    # Select the threshold\n",
    "    threshold, im_thresholded = gf.interactive_threshold(im_start, mean_image)\n",
    "    print('Selected threshold = ' + str(threshold))\n",
    "\n",
    "    # Select the bounds of blob area\n",
    "    print(' ')\n",
    "    print('Select the bounds of blob area that include just a single fish')\n",
    "    min_area, max_area = gf.interactive_blob_filter(im_start, mean_image, threshold)\n",
    "    print('Selected min_area = ' + str(min_area))\n",
    "    print('Selected max_area = ' + str(max_area))\n",
    "\n",
    "    # Save results to experiment_log.csv\n",
    "    cat_raw.loc[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num), 'threshold'] = threshold\n",
    "    cat_raw.loc[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num), 'min_area'] = min_area\n",
    "    cat_raw.loc[(cat_raw['date'] == sch_date) & (cat_raw['sch_num'] == sch_num), 'max_area'] = max_area\n",
    "\n",
    "    # Write cat_raw, if it has the same dimensions, or one new column\n",
    "    cat_raw.to_csv(path['cat'], index=False)\n",
    "    print(' ')\n",
    "    print('Added threshold and area values to experiment_log.csv')\n",
    "\n",
    "else:\n",
    "    print(' ')\n",
    "    print('Threshold and area values already exist in experiment_log.csv for the current date and schedule number.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate binary videos\n",
    "\n",
    "Here we use the threshold and area values to generate black-and-white images of the school."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mask\n",
    "mask_filename = generate_filename(sch_date, sch_num, trial_num=None)\n",
    "mask_path = path['mask'] + os.sep + mask_filename + '_mask.jpg'\n",
    "im_mask, mask_perim = vp.get_mask(mask_path)\n",
    "\n",
    "# Get the mean image\n",
    "mean_image_path = path['mean'] + os.sep + mask_filename + '_mean.jpg'\n",
    "mean_image = cv2.imread(mean_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Single video\n",
    "index = 0\n",
    "row = cat_curr.iloc[0]\n",
    "\n",
    "# Paths for input and output videos\n",
    "vid_path_in = vid_path + os.sep + row['video_filename'] + '.' + vid_ext_raw\n",
    "vid_file_out = generate_filename(row['date'], row['sch_num'], trial_num=row['trial_num'])\n",
    "vid_path_out = local_path + os.sep + vid_file_out + '.' + vid_ext_proc\n",
    "\n",
    "# Set bounds of the area for blobs\n",
    "min_area = int(row['min_area']/4)\n",
    "max_area = int(4*row['max_area'])\n",
    "\n",
    "print('Video in: '  + vid_path_in)\n",
    "print('Video out: ' + vid_path_out)\n",
    "\n",
    "status_txt = 'Trial ' + str(row['trial_num'])\n",
    "\n",
    "# Generate and save binary movie\n",
    "vp.make_binary_movie(vid_path_in, vid_path_out, mean_image, row['threshold'], min_area, max_area, \\\n",
    "                        im_mask=im_mask, mask_perim=mask_perim, im_crop=True, status_txt=status_txt, echo=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One video at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mask\n",
    "mask_filename = generate_filename(sch_date, sch_num, trial_num=None)\n",
    "mask_path = path['mask'] + os.sep + mask_filename + '_mask.jpg'\n",
    "im_mask, mask_perim = vp.get_mask(mask_path)\n",
    "\n",
    "# Get the mean image\n",
    "mean_image_path = path['mean'] + os.sep + mask_filename + '_mean.jpg'\n",
    "mean_image = cv2.imread(mean_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Loop thru each row of cat_curr\n",
    "for index, row in cat_curr.iterrows():\n",
    "\n",
    "    # index = 0\n",
    "    # row = cat_curr.iloc[0]\n",
    "\n",
    "    # Paths for input and output videos\n",
    "    vid_path_in = vid_path + os.sep + row['video_filename'] + '.' + vid_ext_raw\n",
    "    vid_file_out = generate_filename(row['date'], row['sch_num'], trial_num=row['trial_num'])\n",
    "    vid_path_out = local_path + os.sep + vid_file_out + '.' + vid_ext_proc\n",
    "\n",
    "    # Set bounds of the area for blobs\n",
    "    min_area = int(row['min_area']/4)\n",
    "    max_area = int(4*row['max_area'])\n",
    "\n",
    "    print('Video in: '  + vid_path_in)\n",
    "    print('Video out: ' + vid_path_out)\n",
    "\n",
    "    status_txt = 'Trial ' + str(row['trial_num'])\n",
    "\n",
    "    # Generate and save binary movie\n",
    "    vp.make_binary_movie(vid_path_in, vid_path_out, mean_image, row['threshold'], min_area, max_area, \\\n",
    "                         im_mask=im_mask, mask_perim=mask_perim, im_crop=True, status_txt=status_txt, echo=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel processing (original version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trial 1: Finished frame 1 of 16161. Estimated time remaining: 78.2 min\n",
      "   Trial 2: Finished frame 1 of 9027. Estimated time remaining: 43.9 min\n",
      "   Trial 3: Finished frame 1 of 9028. Estimated time remaining: 53.6 min\n",
      "   Trial 1: Finished frame 101 of 16161. Estimated time remaining: 101.6 min\n",
      "   Trial 2: Finished frame 101 of 9027. Estimated time remaining: 59.3 min\n",
      "   Trial 3: Finished frame 101 of 9028. Estimated time remaining: 58.9 min\n",
      "   Trial 1 Frame 131 : Decreasing threshold to 19.0\n",
      "   Trial 1: Finished frame 201 of 16161. Estimated time remaining: 100.8 min\n",
      "   Trial 2: Finished frame 201 of 9027. Estimated time remaining: 58.2 min\n",
      "   Trial 3: Finished frame 201 of 9028. Estimated time remaining: 57.9 min\n",
      "   Trial 3 Frame 253 : Increasing threshold to 21.0\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the mask\n",
    "mask_filename = generate_filename(sch_date, sch_num, trial_num=None)\n",
    "mask_path = path['mask'] + os.sep + mask_filename + '_mask.jpg'\n",
    "im_mask, mask_perim = vp.get_mask(mask_path)\n",
    "\n",
    "# Get the mean image\n",
    "mean_image_path = path['mean'] + os.sep + mask_filename + '_mean.jpg'\n",
    "mean_image = cv2.imread(mean_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Define a function to process each row in parallel\n",
    "def process_row(row):\n",
    "    # Paths for input and output videos\n",
    "    vid_path_in = vid_path + os.sep + row['video_filename'] + '.' + vid_ext_raw\n",
    "    vid_file_out = generate_filename(row['date'], row['sch_num'], trial_num=row['trial_num'])\n",
    "    vid_path_out = local_path + os.sep + vid_file_out + '.' + vid_ext_proc\n",
    "\n",
    "    # Set bounds of the area for blobs\n",
    "    min_area = int(row['min_area'] / 4)\n",
    "    max_area = int(4 * row['max_area'])\n",
    "    \n",
    "    \n",
    "    status_txt = 'Trial ' + str(row['trial_num'])\n",
    "\n",
    "    # Generate and save binary movie\n",
    "    vp.make_binary_movie(vid_path_in, vid_path_out, mean_image, row['threshold'], min_area, max_area,\n",
    "        im_mask=im_mask, mask_perim=mask_perim, im_crop=True, status_txt=status_txt, echo=True)\n",
    "\n",
    "# Create a ThreadPoolExecutor to execute the iterations in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Loop thru each row of cat_curr and submit each iteration as a separate task\n",
    "    futures = [executor.submit(process_row, row) for _, row in cat_curr.iterrows()]\n",
    "\n",
    "    # Wait for all tasks to complete\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "# Calculate the total execution time\n",
    "execution_time = (time.time() - start_time)/60/60\n",
    "print(\"Total execution time: {:.2f} hours\".format(execution_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel processing (second version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "import threading\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the mask\n",
    "mask_filename = generate_filename(sch_date, sch_num, trial_num=None)\n",
    "mask_path = path['mask'] + os.sep + mask_filename + '_mask.jpg'\n",
    "im_mask, mask_perim = vp.get_mask(mask_path)\n",
    "\n",
    "# Get the mean image\n",
    "mean_image_path = path['mean'] + os.sep + mask_filename + '_mean.jpg'\n",
    "mean_image = cv2.imread(mean_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Define a lock to synchronize file writing\n",
    "file_lock = threading.Lock()\n",
    "\n",
    "# Define a function to process each row in parallel\n",
    "def process_row(row):\n",
    "    # Paths for input and output videos\n",
    "    vid_path_in = vid_path + os.sep + row['video_filename'] + '.' + vid_ext_raw\n",
    "    vid_file_out = generate_filename(row['date'], row['sch_num'], trial_num=row['trial_num'])\n",
    "    vid_path_out = path['vidout'] + os.sep + vid_file_out + '.' + vid_ext_proc\n",
    "\n",
    "    # Set bounds of the area for blobs\n",
    "    min_area = int(row['min_area'] / 4)\n",
    "    max_area = int(4 * row['max_area'])\n",
    "    \n",
    "    status_txt = 'Trial ' + str(row['trial_num'])\n",
    "\n",
    "    # Generate and save binary movie\n",
    "    with file_lock:\n",
    "        vp.make_binary_movie(\n",
    "            vid_path_in, vid_path_out, mean_image, row['threshold'], min_area, max_area,\n",
    "            im_mask=im_mask, mask_perim=mask_perim, im_crop=True, status_txt=status_txt\n",
    "        )\n",
    "\n",
    "# Create a ThreadPoolExecutor to execute the iterations in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Loop through each unique source movie and submit each movie as a separate task\n",
    "    source_movies = cat_curr['video_filename'].unique()\n",
    "    futures = [executor.submit(process_row, row) for _, row in cat_curr.iterrows() if row['video_filename'] in source_movies]\n",
    "\n",
    "    # Wait for all tasks to complete\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "# Calculate the total execution time\n",
    "execution_time = (time.time() - start_time) / 60 / 60\n",
    "print(\"Total execution time: {:.2f} hours\".format(execution_time))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TGrabs and TRex\n",
    "\n",
    "## Parameters\n",
    "\n",
    "TGrabs parameters are described in the [TRex documentation](https://trex.run/docs/parameters_tgrabs.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter list for TGrabs \n",
    "param_list_tgrabs = [\n",
    "    #['threshold','20'],\n",
    "    ['averaging_method','mode'],\n",
    "    ['average_samples','150']\n",
    "   # ['blob_size_range','[0.03,1.5]'],\n",
    "   # ['meta_conditions','scaling_exp'],\n",
    "   # ['meta_species','rummy_nose_tetra'],\n",
    "   # ['meta_misc','school_ABC']\n",
    "    ]\n",
    "\n",
    "# print(param_list_tgrabs)\n",
    "\n",
    "# Specify list of parameter values for TRex, all listed as strings\n",
    "param_list_trex = [\n",
    "    #['track_threshold','20'],\n",
    "    #['blob_size_ranges','[0.03,1.5]'],\n",
    "    #['track_max_speed','70'],\n",
    "    ['output_format','npz'],\n",
    "    ['output_invalid_value','nan'],\n",
    "    # ['gui_zoom_limit','[100,100]'],\n",
    "    ['gui_show_posture','false'],\n",
    "    ['gui_show_paths','false'],\n",
    "    ['gui_show_outline', 'true'], \n",
    "    ['gui_show_midline', 'true'], \n",
    "    ['gui_show_blobs', 'true'],\n",
    "    ['gui_show_number_individuals', 'true']\n",
    "    ]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TGrabs generation of movies for TRex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute TGrabs\n",
    "Cell below generates dv videos, which will be used by TRex, from compressed videos.\n",
    "This will be completed for each row of cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input parameter list as dataframe\n",
    "param_input = pd.DataFrame(param_list_tgrabs, columns=['param_name', 'param_val'])\n",
    "# param_input = pd.DataFrame([])\n",
    "\n",
    "# Add the TRex parameter listing to the TGrabs parameters\n",
    "# (might improve the preliminary tracking)\n",
    "param_input.append(param_list_trex)\n",
    "\n",
    "# Extract experiment catalog info\n",
    "cat = af.get_cat_info(path['cat'], include_mode='analyze')\n",
    "\n",
    "# Loop thru each video listed in cat\n",
    "for c_row in cat.index:\n",
    "\n",
    "    # Define trial filename\n",
    "    trialnum = str(int(cat.trial_num[c_row]))\n",
    "    trialnum = '00' + trialnum[-3:]\n",
    "\n",
    "    schnum = str(int(cat.sch_num[c_row]))\n",
    "    schnum = '00' + schnum[-3:]\n",
    "\n",
    "    datetrial_name = cat.date[c_row] + '_sch' + schnum + '_tr' + trialnum\n",
    "\n",
    "    # Define and check input path\n",
    "    path_in = local_path + os.sep + datetrial_name + '.mp4'\n",
    "    if not os.path.isfile(path_in):\n",
    "        raise OSError('Video file does not exist: ' + path_in)\n",
    "\n",
    "    # Output path\n",
    "    path_out = path['vidpv'] + os.sep + datetrial_name + '.pv'\n",
    "\n",
    "    # Path to save settings table\n",
    "    path_settings = path['settings'] + os.sep + datetrial_name + '_tgrabs_settings.csv'\n",
    "\n",
    "    # Start formulating the TGrabs command\n",
    "    command = f'tgrabs -i {path_in} -o {path_out} '\n",
    "\n",
    "    # Add additional command\n",
    "    # command += '-averaging_method mode '\n",
    "\n",
    "     # Get max number of fish from spreadsheet\n",
    "    command += f'-track_max_individuals {str(int(cat.fish_num[c_row]))} '\n",
    "\n",
    "     # Get real width of processed frame (in cm) from spreadsheet\n",
    "    command += f'-meta_real_width {str(int(cat.fr_width_cm[c_row]))} '\n",
    "\n",
    "    # Loop thru each parameter value included in cat\n",
    "    for idx in param_input.index:\n",
    "        command += '-' + str(param_input.param_name[idx]) + ' ' + str(param_input.param_val[idx]) + ' '\n",
    "\n",
    "    # Write settings to csv\n",
    "    param_input.to_csv(path_settings, index=False)\n",
    "    \n",
    "    # Execute at the command line\n",
    "    #os.system(command)\n",
    "    print(command)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running TRex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch execution of experiment videos with TRex\n",
    "\n",
    "Be sure that experiment_log.csv includes the name of the settings file, in the settings directory, that TRex can use to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame that holds the parameter values\n",
    "params_trex = pd.DataFrame(param_list_trex, \n",
    "                    columns=['param_name', 'param_val'])\n",
    "\n",
    "# Extract experiment catalog info\n",
    "cat = af.get_cat_info(path['cat'], include_mode='analyze')\n",
    "\n",
    "# Loop thru each video listed in cat\n",
    "for c_row in cat.index:\n",
    "\n",
    "    # Define trial filename\n",
    "    trialnum = str(int(cat.trial_num[c_row]))\n",
    "    trialnum = '00' + trialnum[-3:]\n",
    "\n",
    "    schnum = str(int(cat.sch_num[c_row]))\n",
    "    schnum = '00' + schnum[-3:]\n",
    "\n",
    "    datetrial_name = cat.date[c_row] + '_sch' + schnum + '_tr' + trialnum\n",
    "\n",
    "    # Define and check input path\n",
    "    path_in = path['vidpv'] + os.sep + datetrial_name + '.pv'\n",
    "\n",
    "    # Check for input file\n",
    "    if not os.path.isfile(path_in):\n",
    "        raise OSError('Video file does not exist: ' + path_in)\n",
    "    \n",
    "    # Where data will be saved\n",
    "    data_path = path['data_raw'] \n",
    "\n",
    "    # Overwrite number of fish\n",
    "    # params_trex.track_max_individuals = str(int(cat.fish_num[c_row]))\n",
    "\n",
    "    # Settings path\n",
    "    path_settings = path['settings'] + os.sep + datetrial_name + '.settings'\n",
    "    #path_settings = datetrial_name + '.settings'\n",
    "\n",
    "    # Start formulating the TGrabs command\n",
    "    #command = f'trex -i {path_in} -output_dir {data_path} -settings_file {path_settings} '\n",
    "    command = f'trex -i {path_in} -output_dir {data_path} '\n",
    "\n",
    "    # Add path for settings\n",
    "    # command += f'-settings_file {path_settings} '\n",
    "\n",
    "    # Get max number of fish from spreadsheet\n",
    "    command += f'-track_max_individuals {str(int(cat.fish_num[c_row]))} '\n",
    "\n",
    "    # Loop thru each parameter value included in cat\n",
    "    for idx in params_trex.index:\n",
    "        command += '-' + str(params_trex.param_name[idx]) + ' ' + str(params_trex.param_val[idx]) + ' '\n",
    "\n",
    "    # Execute at the command line\n",
    "    result = os.system(command)\n",
    "    #print(command)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data in mat format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "import glob\n",
    "\n",
    "# Extract experiment catalog info \n",
    "cat = af.get_cat_info(path['cat'], include_mode='analyze')\n",
    "\n",
    "\n",
    "# Convert all npz files for an experiment to mat files.\n",
    "da.raw_to_mat(cat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "71dac57fef06cf0555e23a411fcaf11d6b3df35474a6cffaa58a5c856d74addb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
